{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/spam-filter/emails.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls","execution_count":19,"outputs":[{"output_type":"stream","text":"__notebook_source__.ipynb  model.h5  model_in_json.json\r\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#pandas for dataframing \n#use keras for modeling\nimport pandas as pd \nimport keras","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#the spam email filter\ndf = pd.read_csv(\"../input/spam-filter/emails.csv\")","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_messages = df['text']","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preprocessed the emails using reggex\npreprocessed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$', 'emailaddr')\npreprocessed = preprocessed.str.replace(r'^(http(s?)\\:\\/\\/)*[0-9a-zA-Z]([-.\\w]*[0-9a-zA-Z])*(:(0-9)*)*(\\/?)([a-zA-Z0-9\\-\\.\\?\\,\\'\\/\\\\\\+&amp;%\\$#_]*)?', 'webaddr')\npreprocessed = preprocessed.str.replace(r\"\\(([0-9]{2}|0{1}((x|[0-9]){2}[0-9]{2}))\\)\\s*[0-9]{3,4}[- ]*[0-9]{4}\", 'phonenum')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessed = preprocessed.str.replace(r'[^\\w\\d\\s]', ' ')\n# replace double spaces\npreprocessed = preprocessed.str.replace(r'\\s+', ' ')\npreprocessed = preprocessed.str.replace(r'_', ' ')\n\n#no begin or end whitespaces\npreprocessed = preprocessed.str.replace(r'^\\s+|\\s+?$', '')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove word stems using a Porter stemmer \n#keep only the root word\nimport nltk\nps = nltk.PorterStemmer()\n\npreprocessed =preprocessed.apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have the stop words deleter imbeded in Count Vectorizer\n#It return a matrix of counter tokens having the max_features attr\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\n \nvectorizer = CountVectorizer(binary=True, stop_words=stopwords.words('english'), \n                             lowercase=False, min_df=3, max_df=0.9, max_features=1500)\npreprocessed1 = vectorizer.fit_transform(preprocessed)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_text, y_train,y_test = train_test_split(preprocessed1, df['spam'], random_state= 42, test_size = 0.2)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dropout\nhelp(Dropout)","execution_count":12,"outputs":[{"output_type":"stream","text":"Help on class Dropout in module keras.layers.core:\n\nclass Dropout(keras.engine.base_layer.Layer)\n |  Applies Dropout to the input.\n |  \n |  Dropout consists in randomly setting\n |  a fraction `rate` of input units to 0 at each update during training time,\n |  which helps prevent overfitting.\n |  \n |  # Arguments\n |      rate: float between 0 and 1. Fraction of the input units to drop.\n |      noise_shape: 1D integer tensor representing the shape of the\n |          binary dropout mask that will be multiplied with the input.\n |          For instance, if your inputs have shape\n |          `(batch_size, timesteps, features)` and\n |          you want the dropout mask to be the same for all timesteps,\n |          you can use `noise_shape=(batch_size, 1, features)`.\n |      seed: A Python integer to use as random seed.\n |  \n |  # References\n |      - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](\n |         http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n |  \n |  Method resolution order:\n |      Dropout\n |      keras.engine.base_layer.Layer\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, rate, noise_shape=None, seed=None, **kwargs)\n |      Initialize self.  See help(type(self)) for accurate signature.\n |  \n |  call(self, inputs, training=None)\n |      This is where the layer's logic lives.\n |      \n |      # Arguments\n |          inputs: Input tensor, or list/tuple of input tensors.\n |          **kwargs: Additional keyword arguments.\n |      \n |      # Returns\n |          A tensor or list/tuple of tensors.\n |  \n |  compute_output_shape(self, input_shape)\n |      Computes the output shape of the layer.\n |      \n |      Assumes that the layer will be built\n |      to match that input shape provided.\n |      \n |      # Arguments\n |          input_shape: Shape tuple (tuple of integers)\n |              or list of shape tuples (one per output tensor of the layer).\n |              Shape tuples can include None for free dimensions,\n |              instead of an integer.\n |      \n |      # Returns\n |          An output shape tuple.\n |  \n |  get_config(self)\n |      Returns the config of the layer.\n |      \n |      A layer config is a Python dictionary (serializable)\n |      containing the configuration of a layer.\n |      The same layer can be reinstantiated later\n |      (without its trained weights) from this configuration.\n |      \n |      The config of a layer does not include connectivity\n |      information, nor the layer class name. These are handled\n |      by `Network` (one layer of abstraction above).\n |      \n |      # Returns\n |          Python dictionary.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from keras.engine.base_layer.Layer:\n |  \n |  __call__(self, inputs, **kwargs)\n |      Wrapper around self.call(), for handling internal references.\n |      \n |      If a Keras tensor is passed:\n |          - We call self._add_inbound_node().\n |          - If necessary, we `build` the layer to match\n |              the _keras_shape of the input(s).\n |          - We update the _keras_shape of every input tensor with\n |              its new shape (obtained via self.compute_output_shape).\n |              This is done as part of _add_inbound_node().\n |          - We update the _keras_history of the output tensor(s)\n |              with the current layer.\n |              This is done as part of _add_inbound_node().\n |      \n |      # Arguments\n |          inputs: Can be a tensor or list/tuple of tensors.\n |          **kwargs: Additional keyword arguments to be passed to `call()`.\n |      \n |      # Returns\n |          Output of the layer's `call` method.\n |      \n |      # Raises\n |          ValueError: in case the layer is missing shape information\n |              for its `build` call.\n |  \n |  __setattr__(self, name, value)\n |      Implement setattr(self, name, value).\n |  \n |  add_loss(self, losses, inputs=None)\n |      Adds losses to the layer.\n |      \n |      The loss may potentially be conditional on some inputs tensors,\n |      for instance activity losses are conditional on the layer's inputs.\n |      \n |      # Arguments\n |          losses: loss tensor or list of loss tensors\n |              to add to the layer.\n |          inputs: input tensor or list of inputs tensors to mark\n |              the losses as conditional on these inputs.\n |              If None is passed, the loss is assumed unconditional\n |              (e.g. L2 weight regularization, which only depends\n |              on the layer's weights variables, not on any inputs tensors).\n |  \n |  add_metric(self, value, name=None)\n |      Adds metric tensor to the layer.\n |      \n |      # Arguments\n |          value: Metric tensor.\n |          name: String metric name.\n |  \n |  add_update(self, updates, inputs=None)\n |      Adds updates to the layer.\n |      \n |      The updates may potentially be conditional on some inputs tensors,\n |      for instance batch norm updates are conditional on the layer's inputs.\n |      \n |      # Arguments\n |          updates: update op or list of update ops\n |              to add to the layer.\n |          inputs: input tensor or list of inputs tensors to mark\n |              the updates as conditional on these inputs.\n |              If None is passed, the updates are assumed unconditional.\n |  \n |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n |      Adds a weight variable to the layer.\n |      \n |      # Arguments\n |          name: String, the name for the weight variable.\n |          shape: The shape tuple of the weight.\n |          dtype: The dtype of the weight.\n |          initializer: An Initializer instance (callable).\n |          regularizer: An optional Regularizer instance.\n |          trainable: A boolean, whether the weight should\n |              be trained via backprop or not (assuming\n |              that the layer itself is also trainable).\n |          constraint: An optional Constraint instance.\n |      \n |      # Returns\n |          The created weight variable.\n |  \n |  assert_input_compatibility(self, inputs)\n |      Checks compatibility between the layer and provided inputs.\n |      \n |      This checks that the tensor(s) `input`\n |      verify the input assumptions of the layer\n |      (if any). If not, exceptions are raised.\n |      \n |      # Arguments\n |          inputs: input tensor or list of input tensors.\n |      \n |      # Raises\n |          ValueError: in case of mismatch between\n |              the provided inputs and the expectations of the layer.\n |  \n |  build(self, input_shape)\n |      Creates the layer weights.\n |      \n |      Must be implemented on all layers that have weights.\n |      \n |      # Arguments\n |          input_shape: Keras tensor (future input to layer)\n |              or list/tuple of Keras tensors to reference\n |              for weight shape computations.\n |  \n |  compute_mask(self, inputs, mask=None)\n |      Computes an output mask tensor.\n |      \n |      # Arguments\n |          inputs: Tensor or list of tensors.\n |          mask: Tensor or list of tensors.\n |      \n |      # Returns\n |          None or a tensor (or list of tensors,\n |              one per output tensor of the layer).\n |  \n |  count_params(self)\n |      Counts the total number of scalars composing the weights.\n |      \n |      # Returns\n |          An integer count.\n |      \n |      # Raises\n |          RuntimeError: if the layer isn't yet built\n |              (in which case its weights aren't yet defined).\n |  \n |  get_input_at(self, node_index)\n |      Retrieves the input tensor(s) of a layer at a given node.\n |      \n |      # Arguments\n |          node_index: Integer, index of the node\n |              from which to retrieve the attribute.\n |              E.g. `node_index=0` will correspond to the\n |              first time the layer was called.\n |      \n |      # Returns\n |          A tensor (or list of tensors if the layer has multiple inputs).\n |  \n |  get_input_mask_at(self, node_index)\n |      Retrieves the input mask tensor(s) of a layer at a given node.\n |      \n |      # Arguments\n |          node_index: Integer, index of the node\n |              from which to retrieve the attribute.\n |              E.g. `node_index=0` will correspond to the\n |              first time the layer was called.\n |      \n |      # Returns\n |          A mask tensor\n |          (or list of tensors if the layer has multiple inputs).\n |  \n |  get_input_shape_at(self, node_index)\n |      Retrieves the input shape(s) of a layer at a given node.\n |      \n |      # Arguments\n |          node_index: Integer, index of the node\n |              from which to retrieve the attribute.\n |              E.g. `node_index=0` will correspond to the\n |              first time the layer was called.\n |      \n |      # Returns\n |          A shape tuple\n |          (or list of shape tuples if the layer has multiple inputs).\n |  \n |  get_losses_for(self, inputs)\n |  \n |  get_output_at(self, node_index)\n |      Retrieves the output tensor(s) of a layer at a given node.\n |      \n |      # Arguments\n |          node_index: Integer, index of the node\n |              from which to retrieve the attribute.\n |              E.g. `node_index=0` will correspond to the\n |              first time the layer was called.\n |      \n |      # Returns\n |          A tensor (or list of tensors if the layer has multiple outputs).\n |  \n |  get_output_mask_at(self, node_index)\n |      Retrieves the output mask tensor(s) of a layer at a given node.\n |      \n |      # Arguments\n |          node_index: Integer, index of the node\n |              from which to retrieve the attribute.\n |              E.g. `node_index=0` will correspond to the\n |              first time the layer was called.\n |      \n |      # Returns\n |          A mask tensor\n |          (or list of tensors if the layer has multiple outputs).\n |  \n |  get_output_shape_at(self, node_index)\n |      Retrieves the output shape(s) of a layer at a given node.\n |      \n |      # Arguments\n |          node_index: Integer, index of the node\n |              from which to retrieve the attribute.\n |              E.g. `node_index=0` will correspond to the\n |              first time the layer was called.\n |      \n |      # Returns\n |          A shape tuple\n |          (or list of shape tuples if the layer has multiple outputs).\n |  \n |  get_updates_for(self, inputs)\n |  \n |  get_weights(self)\n |      Returns the current weights of the layer.\n |      \n |      # Returns\n |          Weights values as a list of numpy arrays.\n |  \n |  set_weights(self, weights)\n |      Sets the weights of the layer, from Numpy arrays.\n |      \n |      # Arguments\n |          weights: a list of Numpy arrays. The number\n |              of arrays and their shape must match\n |              number of the dimensions of the weights\n |              of the layer (i.e. it should match the\n |              output of `get_weights`).\n |      \n |      # Raises\n |          ValueError: If the provided weights list does not match the\n |              layer's specifications.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods inherited from keras.engine.base_layer.Layer:\n |  \n |  from_config(config) from builtins.type\n |      Creates a layer from its config.\n |      \n |      This method is the reverse of `get_config`,\n |      capable of instantiating the same layer from the config\n |      dictionary. It does not handle layer connectivity\n |      (handled by Network), nor weights (handled by `set_weights`).\n |      \n |      # Arguments\n |          config: A Python dictionary, typically the\n |              output of get_config.\n |      \n |      # Returns\n |          A layer instance.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from keras.engine.base_layer.Layer:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  built\n |  \n |  input\n |      Retrieves the input tensor(s) of a layer.\n |      \n |      Only applicable if the layer has exactly one inbound node,\n |      i.e. if it is connected to one incoming layer.\n |      \n |      # Returns\n |          Input tensor or list of input tensors.\n |      \n |      # Raises\n |          AttributeError: if the layer is connected to\n |          more than one incoming layers.\n |  \n |  input_mask\n |      Retrieves the input mask tensor(s) of a layer.\n |      \n |      Only applicable if the layer has exactly one inbound node,\n |      i.e. if it is connected to one incoming layer.\n |      \n |      # Returns\n |          Input mask tensor (potentially None) or list of input\n |          mask tensors.\n |      \n |      # Raises\n |          AttributeError: if the layer is connected to\n |          more than one incoming layers.\n |  \n |  input_shape\n |      Retrieves the input shape tuple(s) of a layer.\n |      \n |      Only applicable if the layer has exactly one inbound node,\n |      i.e. if it is connected to one incoming layer.\n |      \n |      # Returns\n |          Input shape tuple\n |          (or list of input shape tuples, one tuple per input tensor).\n |      \n |      # Raises\n |          AttributeError: if the layer is connected to\n |          more than one incoming layers.\n |  \n |  losses\n |  \n |  metrics\n |  \n |  non_trainable_weights\n |  \n |  output\n |      Retrieves the output tensor(s) of a layer.\n |      \n |      Only applicable if the layer has exactly one inbound node,\n |      i.e. if it is connected to one incoming layer.\n |      \n |      # Returns\n |          Output tensor or list of output tensors.\n |      \n |      # Raises\n |          AttributeError: if the layer is connected to\n |          more than one incoming layers.\n |  \n |  output_mask\n |      Retrieves the output mask tensor(s) of a layer.\n |      \n |      Only applicable if the layer has exactly one inbound node,\n |      i.e. if it is connected to one incoming layer.\n |      \n |      # Returns\n |          Output mask tensor (potentially None) or list of output\n |          mask tensors.\n |      \n |      # Raises\n |          AttributeError: if the layer is connected to\n |          more than one incoming layers.\n |  \n |  output_shape\n |      Retrieves the output shape tuple(s) of a layer.\n |      \n |      Only applicable if the layer has one inbound node,\n |      or if all inbound nodes have the same output shape.\n |      \n |      # Returns\n |          Output shape tuple\n |          (or list of input shape tuples, one tuple per output tensor).\n |      \n |      # Raises\n |          AttributeError: if the layer is connected to\n |          more than one incoming layers.\n |  \n |  trainable_weights\n |  \n |  updates\n |  \n |  weights\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build keras model\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n \nmodel = Sequential()\n \nmodel.add(Dense(units=500, activation='relu', input_dim=len(vectorizer.get_feature_names())))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Dense(units=1, activation='sigmoid'))\n \nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()\n","execution_count":13,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 500)               750500    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 500)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 751,001\nTrainable params: 751,001\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train[:-100], y_train[:-100], \n          epochs=2, batch_size=128, verbose=1, \n          validation_data=(X_train[-100:], y_train[-100:]))\n ","execution_count":14,"outputs":[{"output_type":"stream","text":"Train on 4482 samples, validate on 100 samples\nEpoch 1/2\n4482/4482 [==============================] - 1s 201us/step - loss: 0.2161 - accuracy: 0.9132 - val_loss: 0.0658 - val_accuracy: 1.0000\nEpoch 2/2\n4482/4482 [==============================] - 1s 149us/step - loss: 0.0464 - accuracy: 0.9909 - val_loss: 0.0299 - val_accuracy: 1.0000\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f6e5df1b908>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nscores = model.evaluate(X_text, y_test, verbose=1)\nprint(\"Accuracy:\", scores[1])  # Accuracy: 0.875\n\n ","execution_count":15,"outputs":[{"output_type":"stream","text":"1146/1146 [==============================] - 0s 95us/step\nAccuracy: 0.9860383868217468\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n#let's fit the vectorizer on the dataset words \nvectrizer = vectorizer.fit(preprocessed)\n\n#now pickle\npickle.dump(vectorizer, open(\"vector.pickel\", \"wb\"))","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n# lets save the main model\nmodel_json = model.to_json()\nwith open(\"model_in_json.json\", \"w\") as json_file:\n    json.dump(model_json, json_file)\n\nmodel.save_weights(\"model.h5\")","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#let's create a link to download the main model \n#and vectorizer model\nfrom IPython.display import FileLink\n#create link for the model's weights\nFileLink(\"model.h5\")\n","execution_count":38,"outputs":[{"output_type":"execute_result","execution_count":38,"data":{"text/plain":"/kaggle/working/model.h5","text/html":"<a href='model.h5' target='_blank'>model.h5</a><br>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create link for the model\nFileLink(\"model_in_json.json\")","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"/kaggle/working/model_in_json.json","text/html":"<a href='model_in_json.json' target='_blank'>model_in_json.json</a><br>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create link for the the vectorizer\nFileLink(\"vector.pickel\")","execution_count":40,"outputs":[{"output_type":"execute_result","execution_count":40,"data":{"text/plain":"/kaggle/working/vector.pickel","text/html":"<a href='vector.pickel' target='_blank'>vector.pickel</a><br>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}